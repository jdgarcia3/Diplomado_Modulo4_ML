{"cells":[{"cell_type":"markdown","source":["# Agrupamiento - K-Medias\n","\n","Dataset:\n","El conjunto de datos ‚ÄúSeeds‚Äù describe 210 muestras de granos de trigo, cada una medida con 7 caracter√≠sticas.\n","\n","Cada fila corresponde a un grano de trigo y se midieron variables de su geometr√≠a a partir de im√°genes escaneadas.\n","\n","üîë Columnas del dataset\n","\n","\n","\n","*   √Årea (A) ‚Üí √Årea de la semilla.\n","*   Per√≠metro (P) ‚Üí Longitud del contorno de la semilla.\n","*   Compacidad (C = 4œÄA / P¬≤) ‚Üí Qu√© tan ‚Äúcompacta‚Äù es la semilla (similar a circularidad).\n","*   Longitud del n√∫cleo (L) ‚Üí Largo del grano.\n","*   Ancho del n√∫cleo (W) ‚Üí Ancho del grano.\n","*   Coeficiente de asimetr√≠a (Asymmetry Coefficient) ‚Üí Medida de la simetr√≠a de la semilla.\n","*   Longitud del surco del n√∫cleo (Groove Length) ‚Üí Longitud del surco del grano.\n","*   Clase (label) ‚Üí Tipo de trigo (3 variedades distintas).\n","\n","Para comenzar, ejecute la celda a continuaci√≥n para cargar nuestros datos.\n","\n","> **Cita**: El conjunto de datos de semillas utilizado en este ejercicio fue publicado originalmente por el Instituto de Agrof√≠sica de la Academia Polaca de Ciencias en Lublin por Dua, D. y Graff, C. (2019) y puede descargarse del [Repositorio de Aprendizaje Autom√°tico de la UCI](http://archive.ics.uci.edu/ml), Universidad de California en Irvine, Facultad de Ciencias de la Informaci√≥n y la Computaci√≥n."],"metadata":{"id":"F41B_1AuKqXA"}},{"cell_type":"markdown","source":["##Carga de dataset \"Semillas\""],"metadata":{"id":"swmnVT6oXhSw"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# üì• Cargar el dataset Seeds desde un archivo CSV en internet\n","!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/ml-basics/seeds.csv\n","data = pd.read_csv('seeds.csv')\n","\n","# üîé Seleccionar las primeras 6 columnas como caracter√≠sticas (sin incluir la clase)\n","# Estas columnas son las medidas de cada semilla (√°rea, per√≠metro, compacidad, etc.)\n","features = data[data.columns[0:6]]\n","\n","# üé≤ Mostrar una muestra aleatoria de 10 semillas con sus caracter√≠sticas\n","features.sample(10)\n"],"outputs":[],"execution_count":null,"metadata":{"id":"GqohQhJqKqXC"}},{"cell_type":"markdown","source":["##Normalizaci√≥n y Transformaci√≥n"],"metadata":{"id":"k1erKuXuXanv"}},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\n","from sklearn.decomposition import PCA\n","\n","# ‚öñÔ∏è Normalizar las caracter√≠sticas num√©ricas\n","# MinMaxScaler lleva cada columna a un rango entre 0 y 1,\n","# para que todas las variables tengan la misma importancia en el an√°lisis.\n","scaled_features = MinMaxScaler().fit_transform(features[data.columns[0:6]])\n","\n","# üìâ Reducir la dimensionalidad con PCA (An√°lisis de Componentes Principales)\n","# n_components=2 significa que reduciremos los 6 atributos a 2 componentes principales\n","# Esto permite visualizar los datos en 2D sin perder demasiada informaci√≥n.\n","pca = PCA(n_components=2).fit(scaled_features)\n","\n","# ‚ú® Transformar los datos escalados en el nuevo espacio de 2 componentes principales\n","features_2d = pca.transform(scaled_features)\n","\n","# üëÄ Mostrar las 10 primeras semillas representadas en este espacio 2D\n","# Cada fila ahora tiene solo 2 valores (PC1 y PC2) en lugar de 6 atributos originales\n","features_2d[0:10]"],"metadata":{"id":"dG-M_JBkXYz4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Agrupamiento de K-Medias\n","\n","El algoritmo que utilizaremos para crear nuestros cl√∫steres de prueba es *K-Medias*. Este es un algoritmo de agrupamiento com√∫n que separa un conjunto de datos en *K* cl√∫steres de igual varianza. El n√∫mero de cl√∫steres, *K*, lo define el usuario. El algoritmo consta de los siguientes pasos:\n","\n","1. Se selecciona aleatoriamente un conjunto de K centroides.\n","2. Los cl√∫steres se forman asignando los puntos de datos a su centroide m√°s cercano.\n","3. Se calcula la media de cada cl√∫ster y el centroide se desplaza hasta ella.\n","4. Los pasos 2 y 3 se repiten hasta que se cumple un criterio de parada. Normalmente, el algoritmo finaliza cuando cada nueva iteraci√≥n produce un movimiento insignificante de los centroides y los cl√∫steres se vuelven est√°ticos.\n","5. Cuando los cl√∫steres dejan de cambiar, el algoritmo ha *convergido*, definiendo sus ubicaciones. Tenga en cuenta que el punto de inicio aleatorio de los centroides implica que volver a ejecutar el algoritmo podr√≠a generar cl√∫steres ligeramente diferentes. Por lo tanto, el entrenamiento suele implicar m√∫ltiples iteraciones, reinicializando los centroides cada vez, y se selecciona el modelo con la mejor WCSS (suma de cuadrados dentro del cl√∫ster).\n","\n","Intentemos usar K-Means en nuestros datos de semillas con un valor K de 3."],"metadata":{"id":"z53m9WvLKqXD"}},{"cell_type":"code","source":["from sklearn.cluster import KMeans\n","\n","# üß© Crear un modelo de K-Means con 3 centroides\n","# n_clusters=3 ‚Üí porque sabemos que existen 3 variedades de semillas de trigo\n","# init='k-means++' ‚Üí estrategia para inicializar los centroides de forma inteligente,\n","#                    evitando que caigan muy juntos y mejorando la convergencia.\n","# n_init=100 ‚Üí el algoritmo se ejecuta 100 veces con centroides iniciales diferentes\n","#              y se elige la mejor soluci√≥n (con menor inercia).\n","# max_iter=1000 ‚Üí n√∫mero m√°ximo de iteraciones por cada ejecuci√≥n.\n","model = KMeans(n_clusters=3, init='k-means++', n_init=100, max_iter=1000)\n","\n","# ‚öôÔ∏è Ajustar el modelo a los datos (features) y predecir el cl√∫ster de cada semilla\n","# Esto significa que cada fila del dataset es asignada a un grupo (0, 1 o 2)\n","km_clusters = model.fit_predict(features.values)\n","\n","# üëÄ Ver las asignaciones de cl√∫ster\n","# La salida ser√° un arreglo de n√∫meros (0, 1 o 2),\n","# indicando a qu√© grupo pertenece cada semilla.\n","km_clusters\n"],"outputs":[],"execution_count":null,"metadata":{"id":"_4ZpP_52KqXD"}},{"cell_type":"code","source":["# ============================================================\n","# üìä VISUALIZACI√ìN DE CL√öSTERES CON K-MEANS\n","# ============================================================\n","\n","# Importamos la librer√≠a para gr√°ficos\n","import matplotlib.pyplot as plt\n","\n","# Esta l√≠nea es especial para Jupyter Notebook:\n","# asegura que los gr√°ficos se muestren justo debajo de la celda donde se ejecuta.\n","%matplotlib inline\n","\n","# ------------------------------------------------------------\n","# Definimos una funci√≥n para graficar los cl√∫steres encontrados\n","# ------------------------------------------------------------\n","def plot_clusters(samples, clusters):\n","    # Diccionario que asigna un color a cada cl√∫ster\n","    col_dic = {0:'blue', 1:'green', 2:'orange'}\n","    # Diccionario que asigna un s√≠mbolo/forma a cada cl√∫ster\n","    mrk_dic = {0:'*', 1:'x', 2:'+'}\n","\n","    # Crear una lista de colores seg√∫n el cl√∫ster asignado a cada semilla\n","    colors = [col_dic[x] for x in clusters]\n","    # Crear una lista de marcadores seg√∫n el cl√∫ster asignado a cada semilla\n","    markers = [mrk_dic[x] for x in clusters]\n","\n","    # üîÑ Dibujar cada semilla en el plano 2D\n","    for sample in range(len(clusters)):\n","        plt.scatter(\n","            samples[sample][0],    # posici√≥n en el eje X (1er componente principal)\n","            samples[sample][1],    # posici√≥n en el eje Y (2do componente principal)\n","            color=colors[sample],  # color de acuerdo al cl√∫ster\n","            marker=markers[sample],# marcador de acuerdo al cl√∫ster\n","            s=100                  # tama√±o del punto\n","        )\n","\n","    # Etiquetas de los ejes\n","    plt.xlabel('Dimension 1')\n","    plt.ylabel('Dimension 2')\n","    # T√≠tulo del gr√°fico\n","    plt.title('Assignments')\n","    # Mostrar el gr√°fico final\n","    plt.show()\n","\n","# ------------------------------------------------------------\n","# üöÄ Llamamos a la funci√≥n\n","# ------------------------------------------------------------\n","# - features_2d: coordenadas en 2D de cada semilla (tras aplicar PCA)\n","# - km_clusters: grupo asignado por K-Means a cada semilla\n","plot_clusters(features_2d, km_clusters)\n","\n"],"outputs":[],"execution_count":null,"metadata":{"id":"gc_JR56tKqXD"}},{"cell_type":"markdown","source":["Los datos deben separarse en tres grupos distintos. De lo contrario, repita los dos pasos anteriores.\n","\n","¬øCu√°l es la utilidad pr√°ctica de la agrupaci√≥n en cl√∫steres? En algunos casos, tendr√° datos que necesita agrupar en grupos distintos sin saber cu√°ntos hay ni qu√© indican. Por ejemplo, una organizaci√≥n de marketing podr√≠a querer separar a los clientes en segmentos distintos y luego investigar c√≥mo esos segmentos muestran diferentes comportamientos de compra.\n","\n","A veces, la agrupaci√≥n en cl√∫steres se utiliza como primer paso para crear un modelo de clasificaci√≥n. Se empieza por identificar grupos distintos de puntos de datos y luego se asignan etiquetas de clase a esos grupos. Despu√©s, se pueden usar estos datos etiquetados para entrenar un modelo de clasificaci√≥n.\n","\n","En el caso de los datos de semillas, las diferentes especies de semillas ya se conocen y est√°n codificadas como 0 (*Kama*), 1 (*Rosa*) o 2 (*Canadian*), por lo que podemos usar estos identificadores para comparar las clasificaciones de especies con los grupos identificados por nuestro algoritmo no supervisado."],"metadata":{"id":"q_okWRXzKqXE"}},{"cell_type":"code","source":["# ------------------------------------------------------------\n","# Extraer la columna con la especie real de cada semilla\n","# ------------------------------------------------------------\n","seed_species = data[data.columns[7]]\n","# - data.columns[7] ‚Üí corresponde a la columna \"class\" del dataset seeds.csv.\n","# - Esa columna indica la variedad real de trigo (3 clases distintas).\n","# - Guardamos esa informaci√≥n en la variable seed_species.\n","\n","# ------------------------------------------------------------\n","# Graficar las semillas seg√∫n su especie real\n","# ------------------------------------------------------------\n","plot_clusters(features_2d, seed_species.values)\n","# - features_2d ‚Üí las semillas proyectadas en 2 dimensiones (con PCA).\n","# - seed_species.values ‚Üí la etiqueta real de cada semilla (1, 2 o 3).\n","#   üëâ Esto reemplaza los cl√∫steres predichos por K-Means.\n","#   üëâ El gr√°fico mostrar√° c√≥mo se distribuyen las especies reales en el plano 2D.\n"],"outputs":[],"execution_count":null,"metadata":{"id":"uvWeDcdoKqXE"}},{"cell_type":"markdown","source":["##Resultados"],"metadata":{"id":"Yzmwr8rtZcLx"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# ------------------------------------------------------------\n","# Funci√≥n para graficar dos comparaciones lado a lado\n","# ------------------------------------------------------------\n","def compare_clusters(samples, km_clusters, true_labels):\n","    fig, axes = plt.subplots(1, 2, figsize=(12, 5))  # 1 fila, 2 columnas de gr√°ficos\n","\n","    # Diccionario de colores (mismos en ambos gr√°ficos para comparar)\n","    col_dic = {0:'blue', 1:'green', 2:'orange'}\n","    mrk_dic = {0:'*', 1:'x', 2:'+'}\n","\n","    # ----------- Gr√°fico 1: Asignaciones de K-Means -----------\n","    for sample in range(len(km_clusters)):\n","        axes[0].scatter(samples[sample, 0], samples[sample, 1],\n","                        color=col_dic[km_clusters[sample] % 3],  # usamos %3 para mapear colores\n","                        marker=mrk_dic[km_clusters[sample] % 3],\n","                        s=100)\n","    axes[0].set_title(\"Cl√∫steres de K-Means\")\n","    axes[0].set_xlabel(\"Dimension 1\")\n","    axes[0].set_ylabel(\"Dimension 2\")\n","\n","    # ----------- Gr√°fico 2: Clases reales -----------\n","    for sample in range(len(true_labels)):\n","        axes[1].scatter(samples[sample, 0], samples[sample, 1],\n","                        color=col_dic[(true_labels[sample]-1) % 3],  # -1 porque clases son 1,2,3\n","                        marker=mrk_dic[(true_labels[sample]-1) % 3],\n","                        s=100)\n","    axes[1].set_title(\"Clases reales (especies)\")\n","    axes[1].set_xlabel(\"Dimension 1\")\n","    axes[1].set_ylabel(\"Dimension 2\")\n","\n","    plt.show()\n","\n","# üöÄ Llamar a la funci√≥n con:\n","# - features_2d: semillas en 2D (tras PCA)\n","# - km_clusters: grupos encontrados por K-Means\n","# - seed_species.values: etiquetas reales de las semillas\n","compare_clusters(features_2d, km_clusters, seed_species.values)\n"],"metadata":{"id":"cX8K3ahNZfXZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Puede haber algunas diferencias entre las asignaciones de grupos y las etiquetas de clase, pero el modelo K-Means deber√≠a haber hecho un trabajo razonable de agrupamiento de las observaciones de modo que las semillas de la misma especie est√©n generalmente en el mismo grupo."],"metadata":{"id":"xSkOpzyKKqXE"}}],"metadata":{"kernel_info":{"name":"conda-env-py38_default-py"},"kernelspec":{"display_name":"py38_default","language":"python","name":"conda-env-py38_default-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"nteract":{"version":"nteract-front-end@1.0.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}